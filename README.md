#  Desafio TÃ©cnico - Databricks

## ğŸ“Œ DescriÃ§Ã£o do Projeto
Este projeto tem como objetivo a **ingestÃ£o, transformaÃ§Ã£o e agregaÃ§Ã£o de dados** de uma API externa (*Open Brewery DB*) utilizando **Databricks e Delta Lake**. O pipeline segue a arquitetura **Bronze â†’ Prata â†’ Ouro**.

---

## ğŸ› ï¸ **Tecnologias Utilizadas**
- **Databricks**: OrquestraÃ§Ã£o do pipeline e processamento distribuÃ­do.
- **Delta Lake**: Armazenamento otimizado e versionado.
- **PySpark**: Processamento e transformaÃ§Ã£o dos dados.
- **API Open Brewery DB**: Fonte de dados utilizada.
- **Databricks Jobs**: Agendamento e execuÃ§Ã£o automatizada do pipeline.

---

## ğŸ“Š **Arquitetura do Pipeline**
O pipeline Ã© dividido em trÃªs camadas:

###  **Camada Bronze**
ğŸ“¥ **Objetivo**: IngestÃ£o bruta dos dados da API, sem transformaÃ§Ãµes.
- Coleta os dados da **API Open Brewery DB**.
- Implementa **tratamento de erros** e logs no Delta Lake.
- Adiciona um **timestamp de ingestÃ£o** para rastreabilidade.

ğŸ“Œ **Armazenamento**: `/mnt/datalake/bronze/cervejarias`

---

###  **Camada Prata**
ğŸ› ï¸ **Objetivo**: Limpeza e padronizaÃ§Ã£o dos dados.
- Remove **valores nulos e inconsistÃªncias**.
- Padroniza **nomes e formataÃ§Ãµes**.
- Remove **duplicatas** considerando nome, localizaÃ§Ã£o e endereÃ§o.
- Cria **colunas derivadas** como:
  - `Possui_Site?` (booleano indicando se hÃ¡ site cadastrado).
  - `Esta_Ativa?` (se a cervejaria estÃ¡ ativa ou fechada).
  - `Localizacao` (concatenaÃ§Ã£o de paÃ­s, estado e cidade).

ğŸ“Œ **Armazenamento**: `/mnt/datalake/prata/cervejarias`

---

### **Camada Ouro**
ğŸ“Š **Objetivo**: AgregaÃ§Ã£o dos dados para anÃ¡lise.
- **Consolida os dados** removendo colunas desnecessÃ¡rias.
- Realiza **merge incremental** para evitar duplicaÃ§Ãµes.
- Gera uma **visÃ£o agregada** com a **quantidade de cervejarias por tipo e localizaÃ§Ã£o**.

ğŸ“Œ **Armazenamento**:
- `/mnt/datalake/ouro/cervejarias`
- `/mnt/datalake/ouro/cervejarias_agregadas` (dados agregados)

---

## ğŸ”„ **Gerenciamento de Erros e Rollback**
Para garantir resiliÃªncia, o pipeline implementa um **mecanismo de rollback**. Caso uma etapa falhe, o Databricks executa um rollback na camada correspondente.

- **Se a Camada Bronze falhar**, executa `Rollback_Bronze` e tenta continuar.
- **Se a Camada Prata falhar**, executa `Rollback_Prata` e reprocessa os dados.
- **Se a Camada Ouro falhar**, executa `Rollback_Ouro` e tenta reprocessar os dados agregados.

âœ… **Reprocessamento automÃ¡tico**: Se um rollback for bem-sucedido, a camada correspondente Ã© **reexecutada automaticamente**.

---

## **OrquestraÃ§Ã£o do Pipeline**
O pipeline Ã© executado via **Databricks Jobs**, configurado da seguinte forma:

### ğŸ”¹ Fluxo de ExecuÃ§Ã£o:
1. **Camada Bronze** â†’ Captura os dados da API.
2. **Camada Prata** â†’ Limpa e transforma os dados.
3. **Camada Ouro** â†’ Agrega os dados para anÃ¡lise.
4. **Rollback automÃ¡tico** em caso de falha.

### ğŸ”¹ ConfiguraÃ§Ã£o do Job:
- **`max_retries: 3`** â†’ Cada etapa pode ser reexecutada atÃ© 3 vezes.
- **`retry_on_timeout: false`** â†’ NÃ£o reexecuta em caso de timeout.
- **`run_if: ALL_SUCCESS`** â†’ Uma etapa sÃ³ inicia se a anterior for bem-sucedida.
- **`run_if: ALL_FAILED`** â†’ Ativa rollback em caso de falha.

---

## **Time Travel e Versionamento**
O Delta Lake permite recuperar versÃµes anteriores dos dados caso necessÃ¡rio. Isso Ã© Ãºtil para auditoria e rollback manual.
